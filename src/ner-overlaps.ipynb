{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goals\n",
    "\n",
    "To uncover the interplay between NER annotations and coref annotations. Specifically can finding NER directly lead to an estimation of num of clusters, do they all act as an antecedent?\n",
    "\n",
    "# Specifics\n",
    "\n",
    "1. Try to find num. mentions per coref cluster\n",
    "2. Try to coalasce NER mentions (within one coref cluster) into one 'entity' and re-do this exp.\n",
    "3. Try to do this coalasce thing globally within one document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict, Union\n",
    "from scipy.stats import norm\n",
    "\n",
    "from config import LOCATIONS as LOC\n",
    "from utils.misc import pop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_source = 'spacy' \n",
    "# entity_source = 'spacy'\n",
    "\n",
    "\n",
    "exp_name = f'{entity_source}ner_all.json'\n",
    "# exp_name = f'{entity_source}ner_some.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the summary from disk\n",
    "with (LOC.runs / 'ne_coref' / exp_name).open('r', encoding='utf8') as f:\n",
    "    summary = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     64,
     128
    ]
   },
   "outputs": [],
   "source": [
    "def plot_avec_gauss(data: list, bins=None, xlabel: str= None, ylabel: str = None, plot_gauss: bool = True):\n",
    "    \"\"\" \n",
    "        Assumes data is a list of integers \n",
    "        If not, it would create a key and \"encode\" every element with an integer.\n",
    "    \"\"\"\n",
    "    \n",
    "    sns.set_theme()\n",
    "    \n",
    "    \n",
    "    vocab = {}\n",
    "    freq = Counter(data)\n",
    "    if type(data[0]) is not int:\n",
    "\n",
    "        # We can also sort these things by the freq with which they appear\n",
    "        freq = Counter(data)\n",
    "\n",
    "        freq = dict(sorted(freq.items(), key=lambda kv: - kv[1]))\n",
    "        vocab = {k: i for i, k in enumerate(freq.keys())}\n",
    "        data = deepcopy(data)\n",
    "\n",
    "        for i, datum in enumerate(data):\n",
    "            data[i] = vocab[datum]\n",
    "\n",
    "\n",
    "    bins = bins if bins else max(data)\n",
    "\n",
    "    #     fig = plt.figure(figsize=(6,4))\n",
    "    #     fig.set_dpi(150.0)\n",
    "    #     plt.hist(data, bins=bins, density=True, alpha=0.6, color='b') #, x='Clusters in One Document', y='Frequency')\n",
    "\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    fig.set_dpi(150.0)\n",
    "\n",
    "    ax = fig.add_subplot(111, label=\"Hist\")\n",
    "    ax2 = fig.add_subplot(111, label=\"Mean\", frame_on=False)\n",
    "    ax.hist(data, bins=bins)\n",
    "\n",
    "\n",
    "    if plot_gauss:\n",
    "        mean, std = norm.fit(data)\n",
    "        xmin, xmax = 0, max(data)\n",
    "        x = np.linspace(xmin, xmax, bins*5)\n",
    "        p = norm.pdf(x, mean, std)\n",
    "\n",
    "        ax2.plot(x, p, 'k', linewidth=1)\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel)\n",
    "\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "    ax.tick_params(axis='x')\n",
    "    ax.tick_params(axis='y')\n",
    "\n",
    "    if vocab:\n",
    "        plt.xticks(ticks=range(len(vocab)), labels=vocab.keys(), rotation=90, fontsize=8, color='green')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_avec_mean(data: list, bins=None, xlabel: str= None, ylabel: str = None, \n",
    "                   plot_mean: bool = True, xlog: bool = False, ylog: bool = False, \n",
    "                  ignore_outliers: int = 0, tickall_x: bool = False):\n",
    "    vocab = {}\n",
    "\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    freq = Counter(data)\n",
    "    if type(data[0]) is not int:\n",
    "\n",
    "        # We can also sort these things by the freq with which they appear\n",
    "        freq = Counter(data)\n",
    "\n",
    "        freq = dict(sorted(freq.items(), key=lambda kv: - kv[1]))\n",
    "        vocab = {k: i for i, k in enumerate(freq.keys())}\n",
    "        data = deepcopy(data)\n",
    "\n",
    "        for i, datum in enumerate(data):\n",
    "            data[i] = vocab[datum]\n",
    "\n",
    "            \n",
    "    if ignore_outliers:\n",
    "        data = deepcopy(data)\n",
    "        mean = np.mean(data)\n",
    "        std = np.std(data)\n",
    "        popids = [i for i, val in enumerate(data) \n",
    "                  if not (mean - ignore_outliers*std) <= val <= (mean + ignore_outliers*std)]\n",
    "        pop(data, popids)\n",
    "\n",
    "    bins = bins if bins else max(data)\n",
    "\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    fig.set_dpi(150.0)\n",
    "\n",
    "    ax = fig.add_subplot(111, label=\"Hist\")\n",
    "    ax.hist(data, bins=bins)\n",
    "\n",
    "    if plot_mean:\n",
    "        mean = np.mean(data)\n",
    "        ax.axvline(mean, color = 'r', linestyle = 'dashed', linewidth = 1)\n",
    "\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel)\n",
    "\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "    if vocab:\n",
    "        plt.xticks(ticks=range(len(vocab)), labels=vocab.keys(), rotation=90, fontsize=8, color='green')\n",
    "\n",
    "    if xlog and not vocab:\n",
    "        ax.set_xscale('log')\n",
    "    #     ax.set_xticks([2, 4, 6, 10, 20, 50, 100])\n",
    "\n",
    "    if ylog and not vocab:\n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "    if ylog and tickall_x:\n",
    "        plt.xticks(ticks=range(0, max(data), int(np.std(data))), labels=range(0, max(data), int(np.std(data))))\n",
    "\n",
    "    plt.grid(True, which=\"both\", ls=\"-\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_dist(data: list, bins=None, xlabel: str= None, ylabel: str = None, log: bool = False):\n",
    "    vocab = {}\n",
    "    \n",
    "    sns.set_theme()\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    \n",
    "    freq = Counter(data)\n",
    "    freq = dict(sorted(freq.items(), key=lambda kv: - kv[1]))\n",
    "    \n",
    "    if log:\n",
    "        log_freqv = np.log(list(freq.values()))\n",
    "        freq = {k:v for k, v in zip(freq.keys(), log_freqv)}\n",
    "    \n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    fig.set_dpi(150.0)\n",
    "\n",
    "    ax = fig.add_subplot(111, label=\"Hist\")\n",
    "    plt.xticks(ticks=range(len(freq)), labels=freq.keys(), rotation=90, fontsize=8, color='green' )\n",
    "    ax.bar(range(len(freq)), freq.values())\n",
    "\n",
    "    if log:\n",
    "        ax.set_yscale('log')\n",
    "    \n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel)\n",
    "\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Length Distribution\n",
    "Are the documents of similar sizes? How varied are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avec_mean(summary['tokens_per_doc'], bins=50,\n",
    "    xlabel=\"Number of tokens in ONE document\",\n",
    "    ylabel=\"Number of such documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coref Span Length Distribution\n",
    "What does the average length of a coref span look like. Is it long tailed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avec_mean(summary['length_coref_per_span'], bins=30,\n",
    "    xlabel=\"Number of tokens in a coreferent span\",\n",
    "    ylabel=\"Number of such spans (LOG)\", ylog=True, tickall_x = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Span Length Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avec_mean(summary['length_ner_per_span'], bins=30, ylog=True, tickall_x = False,\n",
    "    xlabel=\"Number of tokens in a named entity span\",\n",
    "    ylabel=\"Number of such spans (LOG)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coref Cluster Cardinality\n",
    "Here, you can see the number of elements contained in coref clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avec_mean(summary['elements_per_cluster'],\n",
    "              xlabel=\"Number of spans/mentions in one coref cluster\",\n",
    "              ylabel=\"Number of such coref clusters (LOG)\", bins=50, ylog=True, ignore_outliers=10, plot_mean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coref Cluster Distribution\n",
    "In the first plot, we a distribution of number of coreference clusters in a document. This should give us an idea of how long tailed the distribution is, and how much memory do we aim to allocate per document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_avec_mean(summary['clusters_per_doc'],\n",
    "    xlabel=\"Number of clusters in ONE document\",\n",
    "    ylabel=\"Number of such documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Distribution\n",
    "Here, we do a similar plot denoting the number of named entities found in a plot. Obviously, this serves little purpose except to illustrate the general distribution of entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_avec_mean(summary['named_entities_per_doc'], bins=100,\n",
    "    xlabel=\"Number of named entities in ONE document\",\n",
    "    ylabel=\"Number of such documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Distribution by Tags\n",
    "Which kind of named entities appear most often. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dist(summary['named_entities_per_tag'],\n",
    "    xlabel=\"NER Tag\",\n",
    "    ylabel=\"Number of such entities\", log=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Distribution (clustered or not)\n",
    "The same plot as above, except the clustered and unclustered variants of each kind of entities are plain to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    unmatched_tags = Counter(summary['named_entities_unmatched_per_tag'])\n",
    "    total_tags = Counter(summary['named_entities_per_tag'])\n",
    "    sorted_total_tags = dict(sorted(total_tags.items(), key=lambda kv: - kv[1]))\n",
    "    sorted_unmatched_tags = {k: unmatched_tags[k] for k in sorted_total_tags.keys()}\n",
    "    sorted_matched_tags = {k: v1-v2 for k, v1, v2 in zip(sorted_total_tags.keys(), sorted_total_tags.values(), sorted_unmatched_tags.values())}\n",
    "\n",
    "\n",
    "    sorted_unmatched_tags, sorted_matched_tags\n",
    "\n",
    "\n",
    "    sns.set_theme()\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    fig.set_dpi(150.0)\n",
    "\n",
    "    ax = fig.add_subplot(111, label=\"Hist\")\n",
    "\n",
    "    ax.bar(range(len(sorted_matched_tags)), sorted_matched_tags.values(), label=\"Matched\")\n",
    "    ax.bar(range(len(sorted_matched_tags)), sorted_unmatched_tags.values(), label=\"Unmatched\", bottom=list(sorted_matched_tags.values()))\n",
    "    ax.set_title(\"Matched vs Unmatched entities by tags\")\n",
    "    ax.legend()\n",
    "\n",
    "    plt.xticks(ticks=range(len(sorted_matched_tags)), labels=sorted_matched_tags.keys(), rotation=90, fontsize=8, color='green' )\n",
    "\n",
    "    ax.set_xlabel(\"NER Tag\")\n",
    "\n",
    "    ax.set_ylabel(\"Number of such entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of clusters with no entities\n",
    "total_clusters = np.sum(summary['clusters_per_doc'])\n",
    "unmatched_clusters = np.sum(summary['clusters_unmatched_per_doc'])\n",
    "matched_entities_per_cluster = np.mean([v for v in summary['named_entities_matched_per_cluster'] if v != 0])\n",
    "total_mismatched_clusters = np.sum(summary['clusters_matched_different_tags_per_doc'])\n",
    "\n",
    "\n",
    "print(f\"Total Clusters in Train Set: {total_clusters}\")\n",
    "print(f\"Clusters with no NER matched: {unmatched_clusters}, \"\n",
    "      f\"i.e. {100*unmatched_clusters / total_clusters:.1f} %.\")\n",
    "\n",
    "print(f\"However, amongst the one which have at least one NER entity matched, \" \n",
    "      f\"on average a cluster has {matched_entities_per_cluster:.2f} entities\")\n",
    "print(f\"Finally, number of clusters which has entities containing \"\n",
    "      f\"more than one tags: {total_mismatched_clusters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative: Clusters with no Entities\n",
    "\n",
    "----\n",
    "\n",
    "#### wb/eng/00/eng_0013_0 part 0**\n",
    "\n",
    "... 'He makes **even the weirdest of the weird** feel normal . But unlike **them** , Jackson does n\\'t try' ...\n",
    "\n",
    "... 'Like **children who are incapable of dissimulating <span style=\"color:red\">their</span> basic wants and needs** , Michael \\'s manner of being in the world is' ...\n",
    "\n",
    "    Note: there are overlapped spans here: (i) children who ... needs and (ii) their\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = True\n",
    "\n",
    "b = 3 ?a b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
