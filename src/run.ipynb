{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing paths from /home/priyansh/Dev/research/coref/mtl/src\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import wandb\n",
    "import click\n",
    "import torch\n",
    "import transformers\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from typing import List, Callable, Iterable, Union\n",
    "from mytorch.utils.goodies import mt_save_dir\n",
    "\n",
    "# Local imports\n",
    "try:\n",
    "    import _pathfix\n",
    "except ImportError:\n",
    "    from . import _pathfix\n",
    "from loops import training_loop\n",
    "from models.multitask import BasicMTL\n",
    "from dataiter import MultiTaskDataIter\n",
    "from utils.misc import check_dumped_config\n",
    "from utils.exceptions import ImproperDumpDir\n",
    "from config import LOCATIONS as LOC, CONFIG, KNOWN_SPLITS\n",
    "from eval import Evaluator, NERAcc, NERSpanRecognitionPR, PrunerPR, CorefBCubed, CorefMUC, CorefCeafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15G        7,7G        2,2G        1,0G        5,4G        6,3G\r\n",
      "Swap:          979M         14M        965M\r\n"
     ]
    }
   ],
   "source": [
    "! free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_optimizer(model, optimizer_class: Callable, lr: float, freeze_encoder: bool):\n",
    "    if freeze_encoder:\n",
    "        return optimizer_class(\n",
    "            [param for name, param in model.named_parameters() if not name.startswith(\"encoder\")],\n",
    "            lr=lr\n",
    "        )\n",
    "    else:\n",
    "        return optimizer_class(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "def get_pretrained_dirs(nm: str):\n",
    "    \"\"\"Check if the given nm is stored locally. If so, load that. Else, pass it on as is.\"\"\"\n",
    "    plausible_parent_dir: Path = LOC.root / \"models\" / \"huggingface\" / nm\n",
    "\n",
    "    if (\n",
    "            (plausible_parent_dir / \"config\").exists()\n",
    "            and (plausible_parent_dir / \"tokenizer\").exists()\n",
    "            and (plausible_parent_dir / \"encoder\").exists()\n",
    "    ):\n",
    "        return (\n",
    "            str(plausible_parent_dir / \"config\"),\n",
    "            str(plausible_parent_dir / \"tokenizer\"),\n",
    "            str(plausible_parent_dir / \"encoder\"),\n",
    "        )\n",
    "    else:\n",
    "        return nm, nm, nm\n",
    "\n",
    "\n",
    "def pick_loss_scale(options: dict, tasks: Iterable[str]):\n",
    "    key = 'loss_scales_' + '_'.join(sorted(tasks))\n",
    "    return options[key]\n",
    "\n",
    "\n",
    "def get_saved_wandb_id(loc: Path):\n",
    "    with (loc / 'config.json').open('r', encoding='utf8') as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    return config['wandbid']\n",
    "\n",
    "\n",
    "def get_save_parent_dir(parentdir: Path, tasks: List[str], config: Union[transformers.BertConfig, dict]) -> Path:\n",
    "    \"\"\"\n",
    "        Normally returns parentdir/'_'.join(sorted(tasks)).\n",
    "        E.g. if tasks are ['coref', 'ner']:\n",
    "                parentdir/coref_ner\n",
    "            but if they are arranged like ['ner', coref'], the output would still be\n",
    "                parentdir/coref_ner\n",
    "            if tasks are ['ner', 'pruner', 'coref']:\n",
    "                parentdir/coref_ner_pruner\n",
    "\n",
    "        However, if we find that trim flag is active in config, or that the run is going to wandb-trials\n",
    "            then the output is\n",
    "                parentdir/trial/<tasks concatenated with _ in alphabetical order>\n",
    "    \"\"\"\n",
    "\n",
    "    if config.trim or config.wandb_trial:\n",
    "        return parentdir / 'trial' / '_'.join(sorted(tasks))\n",
    "    else:\n",
    "        return parentdir / '_'.join(sorted(tasks))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Make MTL A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset: str = 'ontonotes'\n",
    "epochs: int = 10\n",
    "encoder: str = \"bert-base-uncased\"\n",
    "tasks: List[str] = ('coref', 'ner', 'pruner')\n",
    "device: str = \"cpu\"\n",
    "trim: bool = True\n",
    "train_encoder: bool = False,\n",
    "ner_unweighted: bool = False\n",
    "filter_candidates_pos = True\n",
    "use_wandb = False\n",
    "save=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled 318 instances from ../data/parsed/ontonotes/development/MultiTaskDatasetDump_coref_ner_pruner.pkl.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyansh/Dev/research/coref/mtl/src/dataiter.py:97: UserWarning: The dataset has been trimmed to only 50 instances. This is NOT a legit experiment any more!\n",
      "  warnings.warn(\"The dataset has been trimmed to only 50 instances. This is NOT a legit experiment any more!\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"binary_hdim\": 2000,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"coref_dropout\": 0.3,\n",
      "  \"device\": \"cpu\",\n",
      "  \"epochs\": 10,\n",
      "  \"filter_candidates_pos_threshold\": 2000,\n",
      "  \"freeze_encoder\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"loss_scales\": [\n",
      "    0.3923397028791302,\n",
      "    0.2153205942417397,\n",
      "    0.3923397028791302\n",
      "  ],\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_span_width\": 5,\n",
      "  \"max_top_antecedents\": 50,\n",
      "  \"metadata_feature_size\": 20,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"ner_class_weights\": [\n",
      "    0.05330982413982514,\n",
      "    24.68555023923445,\n",
      "    30.717313646106216,\n",
      "    51.42822966507177,\n",
      "    20.887773279352228,\n",
      "    43.23902111967818,\n",
      "    101.32128829536528,\n",
      "    1697.1315789473683,\n",
      "    38.79157894736842,\n",
      "    174.06477732793522,\n",
      "    678.8526315789474,\n",
      "    135.77052631578948,\n",
      "    141.42763157894737,\n",
      "    102.85645933014354,\n",
      "    678.8526315789474,\n",
      "    1697.1315789473683,\n",
      "    183.47368421052633,\n",
      "    424.2828947368421,\n",
      "    1357.7052631578947\n",
      "  ],\n",
      "  \"ner_ignore_weights\": false,\n",
      "  \"ner_n_classes\": 19,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pruner_class_weights\": [\n",
      "    0.5103185781885514,\n",
      "    24.728144171779142\n",
      "  ],\n",
      "  \"top_span_ratio\": 0.4,\n",
      "  \"transformers_version\": \"4.13.0\",\n",
      "  \"trim\": true,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"unary_hdim\": 1000,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": \"../models/huggingface/bert-base-uncased/config\"\n",
      "}\n",
      "\n",
      "Training commences!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dir_config, dir_tokenizer, dir_encoder = get_pretrained_dirs(encoder)\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(dir_tokenizer)\n",
    "config = transformers.BertConfig(dir_config)\n",
    "config.max_span_width = 5\n",
    "config.coref_dropout = 0.3\n",
    "config.metadata_feature_size = 20\n",
    "config.unary_hdim = 1000\n",
    "config.binary_hdim = 2000\n",
    "config.top_span_ratio = 0.4\n",
    "config.max_top_antecedents = 50\n",
    "config.device = device\n",
    "config.epochs = epochs\n",
    "config.trim = trim\n",
    "config.freeze_encoder = not train_encoder\n",
    "config.ner_ignore_weights = ner_unweighted\n",
    "config.filter_candidates_pos_threshold = CONFIG['filter_candidates_pos_threshold'] \\\n",
    "    if filter_candidates_pos else -1\n",
    "\n",
    "# Assign loss scales based on task\n",
    "loss_scales = pick_loss_scale(CONFIG, tasks)\n",
    "config.loss_scales = loss_scales.tolist() if not type(loss_scales) is list else loss_scales\n",
    "\n",
    "if 'ner' in tasks or 'pruner' in tasks:\n",
    "    # Need to figure out the number of classes. Load a DL. Get the number. Delete the DL.\n",
    "    temp_ds = MultiTaskDataIter(\n",
    "        src=dataset,\n",
    "        config=config,\n",
    "        tasks=tasks,\n",
    "        split=\"development\",\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    if 'ner' in tasks:\n",
    "        config.ner_n_classes = deepcopy(temp_ds.ner_tag_dict.__len__())\n",
    "        config.ner_class_weights = temp_ds.estimate_class_weights('ner')\n",
    "    else:\n",
    "        config.ner_n_classes = 1\n",
    "        config.ner_class_weights = [1.0, ]\n",
    "    if 'pruner' in tasks:\n",
    "        config.pruner_class_weights = temp_ds.estimate_class_weights('pruner')\n",
    "    del temp_ds\n",
    "else:\n",
    "    config.ner_n_classes = 1\n",
    "    config.ner_class_weights = [1.0, ]\n",
    "\n",
    "# # Make the model\n",
    "model = BasicMTL(dir_encoder, config=config)\n",
    "\n",
    "# Load the data\n",
    "train_ds = partial(\n",
    "    MultiTaskDataIter,\n",
    "    src=dataset,\n",
    "    config=config,\n",
    "    tasks=tasks,\n",
    "    split=KNOWN_SPLITS[dataset].train,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "dev_ds = partial(\n",
    "    MultiTaskDataIter,\n",
    "    src=dataset,\n",
    "    config=config,\n",
    "    tasks=tasks,\n",
    "    split=KNOWN_SPLITS[dataset].dev,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Make the optimizer\n",
    "opt = make_optimizer(model=model, optimizer_class=torch.optim.SGD, lr=0.005, freeze_encoder=config.freeze_encoder)\n",
    "opt = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Make the evaluation suite (may compute multiple metrics corresponding to the tasks)\n",
    "metrics = []\n",
    "if 'ner' in tasks:\n",
    "    metrics += [NERAcc(), NERSpanRecognitionPR()]\n",
    "if 'pruner' in tasks:\n",
    "    metrics += [PrunerPR()]\n",
    "if 'coref' in tasks:\n",
    "    metrics += [CorefBCubed(), CorefMUC(), CorefCeafe()]\n",
    "train_eval = Evaluator(\n",
    "    predict_fn=model.pred_with_labels,\n",
    "    dataset_partial=train_ds,\n",
    "    metrics=metrics,\n",
    "    device=device\n",
    ")\n",
    "dev_eval = Evaluator(\n",
    "    predict_fn=model.pred_with_labels,\n",
    "    dataset_partial=dev_ds,\n",
    "    metrics=metrics,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(config)\n",
    "print(\"Training commences!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "savedir, save_config, save_objs = None, None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled 2455 instances from ../data/parsed/ontonotes/train/MultiTaskDatasetDump_coref_ner_pruner.pkl.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad30f46a1e34f7a81fe2213aa67a589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Following are the differences found in the configs.\n",
      "Old:            ner_n_classes: None\n",
      "New:            ner_n_classes: 19\n",
      "Old:        ner_class_weights: None\n",
      "New:        ner_class_weights: [0.05330982413982514, 24.68555023923445, 30.717313646106216, 51.42822966507177, 20.887773279352228, 43.23902111967818, 101.32128829536528, 1697.1315789473683, 38.79157894736842, 174.06477732793522, 678.8526315789474, 135.77052631578948, 141.42763157894737, 102.85645933014354, 678.8526315789474, 1697.1315789473683, 183.47368421052633, 424.2828947368421, 1357.7052631578947]\n",
      "Old:     pruner_class_weights: None\n",
      "New:     pruner_class_weights: [0.5103185781885514, 24.728144171779142]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyansh/Dev/research/coref/mtl/src/dataiter.py:164: UserWarning: Processed (training ready) found on ../data/parsed/ontonotes/development/MultiTaskDatasetDump_coref_ner_pruner.pkl. But the config files mismatch.Reprocessing will commence now but will take some time. Approx. 5 min.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f119c580fb147bcb4802bbfb641b91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=318.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 512). Running this sequence through the model will result in indexing errors\n",
      "/home/priyansh/Dev/research/coref/mtl/src/dataiter.py:473: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370124688/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  if gold_labels.nonzero().shape[0] == 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOO LONG:  reeeeeeeeeeeeeeaaaal\n",
      "TOO LONG:  586.14_588.20_\n",
      "TOO LONG:  586.14_588.20_a\n",
      "TOO LONG:  586.14_588.20_a:\n",
      "TOO LONG:  820.26_822.65_b\n",
      "TOO LONG:  820.26_822.65_b:\n",
      "TOO LONG:  965.04_967.89_\n",
      "TOO LONG:  965.04_967.89_b\n",
      "TOO LONG:  965.04_967.89_b:\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b42c76810e54bbe9387707c17ca2610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch:   1 | coref Loss: 3.91986 | coref Tr_b_cubed_p: 0.000 | coref Tr_b_cubed_r: 0.027 | coref Tr_b_cubed_f1: 0.001 | coref Tr_muc_p: 0.003 | coref Tr_muc_r: 0.019 | coref Tr_muc_f1: 0.005 | coref Tr_ceafe_p: 0.015 | coref Tr_ceafe_r: 0.007 | coref Tr_ceafe_f1: 0.010\n",
      "\t\t | coref Vl_b_cubed_p: 0.000 | coref Vl_b_cubed_r: 0.027 | coref Vl_b_cubed_f1: 0.001 | coref Vl_muc_p: 0.003 | coref Vl_muc_r: 0.019 | coref Vl_muc_f1: 0.005 | coref Vl_ceafe_p: 0.015 | coref Vl_ceafe_r: 0.007 | coref Vl_ceafe_f1: 0.010\n",
      "\t | ner Loss: 2.94371 | ner Tr_acc: 0.355 | ner Tr_acc_nonzero: 0.043 | ner Tr_spanrec_p: 0.660 | ner Tr_spanrec_r: 0.012\n",
      "\t\t | ner Vl_acc: 0.355 | ner Vl_acc_nonzero: 0.043 | ner Vl_spanrec_p: 0.660 | ner Vl_spanrec_r: 0.012\n",
      "\t | pruner Loss: 0.53346 | pruner Tr_p: 0.095 | pruner Tr_r: 0.018\n",
      "\t\t | pruner Vl_p: 0.095 | pruner Vl_r: 0.018\n",
      "Pulled 2455 instances from ../data/parsed/ontonotes/train/MultiTaskDatasetDump_coref_ner_pruner.pkl.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d755580a6b142909df2c721a14de0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pulled 318 instances from ../data/parsed/ontonotes/development/MultiTaskDatasetDump_coref_ner_pruner.pkl.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef37338b9a904d6d8d613cf250e24a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch:   2 | coref Loss: 3.90847 | coref Tr_b_cubed_p: 0.000 | coref Tr_b_cubed_r: 0.024 | coref Tr_b_cubed_f1: 0.001 | coref Tr_muc_p: 0.003 | coref Tr_muc_r: 0.018 | coref Tr_muc_f1: 0.005 | coref Tr_ceafe_p: 0.017 | coref Tr_ceafe_r: 0.006 | coref Tr_ceafe_f1: 0.009\n",
      "\t\t | coref Vl_b_cubed_p: 0.000 | coref Vl_b_cubed_r: 0.024 | coref Vl_b_cubed_f1: 0.001 | coref Vl_muc_p: 0.003 | coref Vl_muc_r: 0.018 | coref Vl_muc_f1: 0.005 | coref Vl_ceafe_p: 0.017 | coref Vl_ceafe_r: 0.006 | coref Vl_ceafe_f1: 0.009\n",
      "\t | ner Loss: 2.94363 | ner Tr_acc: 0.391 | ner Tr_acc_nonzero: 0.038 | ner Tr_spanrec_p: 0.633 | ner Tr_spanrec_r: 0.013\n",
      "\t\t | ner Vl_acc: 0.391 | ner Vl_acc_nonzero: 0.038 | ner Vl_spanrec_p: 0.633 | ner Vl_spanrec_r: 0.013\n",
      "\t | pruner Loss: 0.38629 | pruner Tr_p: 0.084 | pruner Tr_r: 0.016\n",
      "\t\t | pruner Vl_p: 0.084 | pruner Vl_r: 0.016\n",
      "Pulled 2455 instances from ../data/parsed/ontonotes/train/MultiTaskDatasetDump_coref_ner_pruner.pkl.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1b6e924b654332a474ddab4762bf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pulled 318 instances from ../data/parsed/ontonotes/development/MultiTaskDatasetDump_coref_ner_pruner.pkl.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd447a1692f47d78665f316b8d1c75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch:   3 | coref Loss: 3.89938 | coref Tr_b_cubed_p: 0.000 | coref Tr_b_cubed_r: 0.026 | coref Tr_b_cubed_f1: 0.001 | coref Tr_muc_p: 0.003 | coref Tr_muc_r: 0.016 | coref Tr_muc_f1: 0.004 | coref Tr_ceafe_p: 0.016 | coref Tr_ceafe_r: 0.007 | coref Tr_ceafe_f1: 0.010\n",
      "\t\t | coref Vl_b_cubed_p: 0.000 | coref Vl_b_cubed_r: 0.026 | coref Vl_b_cubed_f1: 0.001 | coref Vl_muc_p: 0.003 | coref Vl_muc_r: 0.016 | coref Vl_muc_f1: 0.004 | coref Vl_ceafe_p: 0.016 | coref Vl_ceafe_r: 0.007 | coref Vl_ceafe_f1: 0.010\n",
      "\t | ner Loss: 2.94308 | ner Tr_acc: 0.438 | ner Tr_acc_nonzero: 0.033 | ner Tr_spanrec_p: 0.619 | ner Tr_spanrec_r: 0.013\n",
      "\t\t | ner Vl_acc: 0.438 | ner Vl_acc_nonzero: 0.033 | ner Vl_spanrec_p: 0.619 | ner Vl_spanrec_r: 0.013\n",
      "\t | pruner Loss: 0.27350 | pruner Tr_p: 0.095 | pruner Tr_r: 0.017\n",
      "\t\t | pruner Vl_p: 0.095 | pruner Vl_r: 0.017\n",
      "Pulled 2455 instances from ../data/parsed/ontonotes/train/MultiTaskDatasetDump_coref_ner_pruner.pkl.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743d6b360df34f30aed564fa5bbd9f3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pulled 318 instances from ../data/parsed/ontonotes/development/MultiTaskDatasetDump_coref_ner_pruner.pkl.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf651f49924244539f3ee686c8a3a0e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch:   4 | coref Loss: 3.86282 | coref Tr_b_cubed_p: 0.001 | coref Tr_b_cubed_r: 0.023 | coref Tr_b_cubed_f1: 0.002 | coref Tr_muc_p: 0.002 | coref Tr_muc_r: 0.014 | coref Tr_muc_f1: 0.004 | coref Tr_ceafe_p: 0.016 | coref Tr_ceafe_r: 0.013 | coref Tr_ceafe_f1: 0.014\n",
      "\t\t | coref Vl_b_cubed_p: 0.001 | coref Vl_b_cubed_r: 0.023 | coref Vl_b_cubed_f1: 0.002 | coref Vl_muc_p: 0.002 | coref Vl_muc_r: 0.014 | coref Vl_muc_f1: 0.004 | coref Vl_ceafe_p: 0.016 | coref Vl_ceafe_r: 0.013 | coref Vl_ceafe_f1: 0.014\n",
      "\t | ner Loss: 2.94290 | ner Tr_acc: 0.465 | ner Tr_acc_nonzero: 0.027 | ner Tr_spanrec_p: 0.586 | ner Tr_spanrec_r: 0.013\n",
      "\t\t | ner Vl_acc: 0.465 | ner Vl_acc_nonzero: 0.027 | ner Vl_spanrec_p: 0.586 | ner Vl_spanrec_r: 0.013\n",
      "\t | pruner Loss: 0.19529 | pruner Tr_p: 0.096 | pruner Tr_r: 0.017\n",
      "\t\t | pruner Vl_p: 0.096 | pruner Vl_r: 0.017\n",
      "Pulled 2455 instances from ../data/parsed/ontonotes/train/MultiTaskDatasetDump_coref_ner_pruner.pkl.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f482782acc845d1bcc552b90fe0b3aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pulled 318 instances from ../data/parsed/ontonotes/development/MultiTaskDatasetDump_coref_ner_pruner.pkl.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb74423dc9c4b6d8ed38002a90cc2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Epoch:   5 | coref Loss: 3.72722 | coref Tr_b_cubed_p: 0.002 | coref Tr_b_cubed_r: 0.013 | coref Tr_b_cubed_f1: 0.003 | coref Tr_muc_p: 0.002 | coref Tr_muc_r: 0.005 | coref Tr_muc_f1: 0.002 | coref Tr_ceafe_p: 0.014 | coref Tr_ceafe_r: 0.011 | coref Tr_ceafe_f1: 0.012\n",
      "\t\t | coref Vl_b_cubed_p: 0.002 | coref Vl_b_cubed_r: 0.013 | coref Vl_b_cubed_f1: 0.003 | coref Vl_muc_p: 0.002 | coref Vl_muc_r: 0.005 | coref Vl_muc_f1: 0.002 | coref Vl_ceafe_p: 0.014 | coref Vl_ceafe_r: 0.011 | coref Vl_ceafe_f1: 0.012\n",
      "\t | ner Loss: 2.94266 | ner Tr_acc: 0.486 | ner Tr_acc_nonzero: 0.026 | ner Tr_spanrec_p: 0.562 | ner Tr_spanrec_r: 0.013\n",
      "\t\t | ner Vl_acc: 0.486 | ner Vl_acc_nonzero: 0.026 | ner Vl_spanrec_p: 0.562 | ner Vl_spanrec_r: 0.013\n",
      "\t | pruner Loss: 0.15243 | pruner Tr_p: 0.103 | pruner Tr_r: 0.019\n",
      "\t\t | pruner Vl_p: 0.103 | pruner Vl_r: 0.019\n",
      "Pulled 2455 instances from ../data/parsed/ontonotes/train/MultiTaskDatasetDump_coref_ner_pruner.pkl.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c74aca32bc4779a0979a23ea6cb77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs = training_loop(\n",
    "    model=model,\n",
    "    epochs=epochs,\n",
    "    trn_dl=train_ds,\n",
    "    forward_fn=model.pred_with_labels,\n",
    "    device=device,\n",
    "    train_eval=train_eval,\n",
    "    dev_eval=dev_eval,\n",
    "    opt=opt,\n",
    "    tasks=tasks,\n",
    "    loss_scales=torch.tensor(loss_scales, dtype=torch.float, device=device),\n",
    "    flag_wandb=use_wandb,\n",
    "    flag_save=save,\n",
    "    save_dir=savedir,\n",
    "    save_config=save_config,\n",
    "    epochs_last_run=config.epoch if hasattr(config, 'epoch') else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "onto_train_di = train_ds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Make MTL B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset: str = 'scierc'\n",
    "epochs: int = 10\n",
    "encoder: str = \"bert-base-uncased\"\n",
    "tasks: List[str] = ('ner',)\n",
    "device: str = \"cpu\"\n",
    "trim: bool = False\n",
    "train_encoder: bool = False\n",
    "ner_unweighted: bool = False\n",
    "filter_candidates_pos = True\n",
    "\n",
    "\n",
    "dir_config, dir_tokenizer, dir_encoder = get_pretrained_dirs(encoder)\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(dir_tokenizer)\n",
    "config = transformers.BertConfig(dir_config)\n",
    "config.max_span_width = 5\n",
    "config.coref_dropout = 0.3\n",
    "config.metadata_feature_size = 20\n",
    "config.unary_hdim = 1000\n",
    "config.binary_hdim = 2000\n",
    "config.top_span_ratio = 0.4\n",
    "config.max_top_antecedents = 50\n",
    "config.device = device\n",
    "config.epochs = epochs\n",
    "config.trim = trim\n",
    "config.freeze_encoder = not train_encoder\n",
    "config.ner_ignore_weights = ner_unweighted\n",
    "config.filter_candidates_pos_threshold = CONFIG['filter_candidates_pos_threshold'] \\\n",
    "    if filter_candidates_pos else -1\n",
    "\n",
    "\n",
    "# if 'ner' in tasks or 'pruner' in tasks:\n",
    "if False:\n",
    "    # Need to figure out the number of classes. Load a DL. Get the number. Delete the DL.\n",
    "    temp_ds = MultiTaskDataIter(\n",
    "        src=dataset,\n",
    "        config=config,\n",
    "        tasks=tasks,\n",
    "        split=\"dev\",\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    if 'ner' in tasks:\n",
    "        config.ner_n_classes = deepcopy(temp_ds.ner_tag_dict.__len__())\n",
    "        config.ner_class_weights = temp_ds.estimate_class_weights('ner')\n",
    "    else:\n",
    "        config.ner_n_classes = 1\n",
    "        config.ner_class_weights = [1.0, ]\n",
    "    if 'pruner' in tasks:\n",
    "        config.pruner_class_weights = temp_ds.estimate_class_weights('pruner')\n",
    "    del temp_ds\n",
    "else:\n",
    "    config.ner_n_classes = 1\n",
    "    config.ner_class_weights = [1.0, ]\n",
    "\n",
    "# # Make the model\n",
    "# model = BasicMTL(dir_encoder, config=config)\n",
    "\n",
    "# Load the data\n",
    "train_ds = partial(\n",
    "    MultiTaskDataIter,\n",
    "    src=dataset,\n",
    "    config=config,\n",
    "    tasks=tasks,\n",
    "    split=\"train\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "sci_train_ds = train_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sci_train_ds[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "la = onto_train_di.__len__()\n",
    "lb = sci_train_ds.__len__()\n",
    "\n",
    "la, lb, la+lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sampling_ratio = [0.5, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "llen = la + lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pointers = [int(x* llen / float(sum(sampling_ratio))) for x in sampling_ratio]\n",
    "pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pointers = [2, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "source_indices = []\n",
    "for i, dataset_specific_ratio in enumerate(pointers):\n",
    "    source_indices += [i]*dataset_specific_ratio\n",
    "    \n",
    "source_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(source_indices)\n",
    "\n",
    "source_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from eval import Evaluator, NERAcc, NERSpanRecognitionPR, PrunerPR, CorefBCubed, CorefMUC, CorefCeafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_bench = Evaluator(\n",
    "    predict_fn = model.pred_with_labels,\n",
    "    dataset_partial = valid_ds,\n",
    "    metrics = [NERAcc(), NERSpanRecognitionPR(), PrunerPR(), CorefBCubed(), CorefMUC(), CorefCeafe()],\n",
    "    device = 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_bench.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Eval for Coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     25,
     40,
     44
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def b_cubed(clusters, mention_to_gold):\n",
    "    num, dem = 0, 0\n",
    "\n",
    "    for c in clusters:\n",
    "        if len(c) == 1:\n",
    "            continue\n",
    "\n",
    "        gold_counts = Counter()\n",
    "        correct = 0\n",
    "        for m in c:\n",
    "            if m in mention_to_gold:\n",
    "                gold_counts[tuple(mention_to_gold[m])] += 1\n",
    "        for c2, count in gold_counts.items():\n",
    "            if len(c2) != 1:\n",
    "                correct += count * count\n",
    "\n",
    "        num += correct / float(len(c))\n",
    "        dem += len(c)\n",
    "\n",
    "    return num, dem\n",
    "\n",
    "\n",
    "def muc(clusters, mention_to_gold):\n",
    "    tp, p = 0, 0\n",
    "    for c in clusters:\n",
    "        p += len(c) - 1\n",
    "        tp += len(c)\n",
    "        linked = set()\n",
    "        for m in c:\n",
    "            if m in mention_to_gold:\n",
    "                linked.add(mention_to_gold[m])\n",
    "            else:\n",
    "                tp -= 1\n",
    "        tp -= len(linked)\n",
    "    return tp, p\n",
    "\n",
    "\n",
    "def phi4(c1, c2):\n",
    "    return 2 * len([m for m in c1 if m in c2]) / float(len(c1) + len(c2))\n",
    "\n",
    "\n",
    "def ceafe(clusters, gold_clusters):\n",
    "    clusters = [c for c in clusters if len(c) != 1]\n",
    "    scores = np.zeros((len(gold_clusters), len(clusters)))\n",
    "    for i in range(len(gold_clusters)):\n",
    "        for j in range(len(clusters)):\n",
    "            scores[i, j] = phi4(gold_clusters[i], clusters[j])\n",
    "    matching = linear_assignment(-scores)\n",
    "    similarity = sum(scores[matching[0], matching[1]])\n",
    "\n",
    "    # similarity = sum(scores[matching[:, 0], matching[:, 1]])\n",
    "    return similarity, len(clusters), similarity, len(gold_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, instance in enumerate(dl):\n",
    "    outputs = model.pred_with_labels(**instance)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "instance['coref'].keys(), outputs['coref'].keys(), outputs.keys(), outputs['coref']['eval'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('=None, '.join(['clusters', 'gold_clusters', 'mention_to_predicted', 'mention_to_gold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ll =  outputs['coref']['eval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ceafe(ll['clusters'], ll['gold_clusters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "phi4(ll['clusters'], ll['gold_clusters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "muc(ll['clusters'], ll['mention_to_gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "b_cubed(ll['clusters'], ll['mention_to_gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}