{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing paths from /home/priyansh/Dev/research/coref/mtl/src\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import click\n",
    "import torch\n",
    "import transformers\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "from typing import List, Callable, Dict, Iterable\n",
    "\n",
    "# Local imports\n",
    "try:\n",
    "    import _pathfix\n",
    "except ImportError:\n",
    "    from . import _pathfix\n",
    "from loops import training_loop\n",
    "from config import LOCATIONS as LOC, CONFIG\n",
    "from models.multitask import BasicMTL\n",
    "from dataiter import MultiTaskDataIter\n",
    "# from eval import ner_all, ner_only_annotated, ner_span_recog_recall, ner_span_recog_precision, \\\n",
    "#     pruner_p, pruner_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              total        used        free      shared  buff/cache   available\r\n",
      "Mem:            15G        8,7G        1,6G        1,0G        5,1G        5,3G\r\n",
      "Swap:          979M        555M        424M\r\n"
     ]
    }
   ],
   "source": [
    "! free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def make_optimizer(model, optimizer_class: Callable, lr: float, freeze_encoder: bool):\n",
    "    if freeze_encoder:\n",
    "        return optimizer_class(\n",
    "            [param for name, param in model.named_parameters() if not name.startswith(\"encoder\")],\n",
    "            lr=lr\n",
    "        )\n",
    "    else:\n",
    "        return optimizer_class(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "def get_pretrained_dirs(nm: str):\n",
    "    \"\"\"Check if the given nm is stored locally. If so, load that. Else, pass it on as is.\"\"\"\n",
    "    plausible_parent_dir: Path = LOC.root / \"models\" / \"huggingface\" / nm\n",
    "\n",
    "    if (\n",
    "            (plausible_parent_dir / \"config\").exists()\n",
    "            and (plausible_parent_dir / \"tokenizer\").exists()\n",
    "            and (plausible_parent_dir / \"encoder\").exists()\n",
    "    ):\n",
    "        return (\n",
    "            str(plausible_parent_dir / \"config\"),\n",
    "            str(plausible_parent_dir / \"tokenizer\"),\n",
    "            str(plausible_parent_dir / \"encoder\"),\n",
    "        )\n",
    "    else:\n",
    "        return nm, nm, nm\n",
    "\n",
    "\n",
    "def compute_metrics(metrics: Dict[str, Callable], logits, labels) -> Dict[str, float]:\n",
    "    return {metric_nm: metric_fn(logits=logits, labels=labels).item() for metric_nm, metric_fn in metrics.items()}\n",
    "\n",
    "\n",
    "def aggregate_metrics(inter_epoch: dict, intra_epoch: dict):\n",
    "    for task_nm in inter_epoch.keys():\n",
    "        for metric_nm, metric_list in intra_epoch[task_nm].items():\n",
    "            inter_epoch[task_nm][metric_nm].append(np.mean(metric_list))\n",
    "    return inter_epoch\n",
    "\n",
    "\n",
    "def simplest_loop(\n",
    "        epochs: int,\n",
    "        tasks: Iterable[str],\n",
    "        opt: torch.optim,\n",
    "        train_fn: Callable,\n",
    "        predict_fn: Callable,\n",
    "        trn_dl: Callable,\n",
    "        dev_dl: Callable,\n",
    "        eval_fns: dict,\n",
    ") -> (list, list, list):\n",
    "    train_loss = {task_nm: [] for task_nm in tasks}\n",
    "    train_metrics = {task_nm: {metric_nm: [] for metric_nm in eval_fns[task_nm].keys()} for task_nm in tasks}\n",
    "    valid_metrics = {task_nm: {metric_nm: [] for metric_nm in eval_fns[task_nm].keys()} for task_nm in tasks}\n",
    "\n",
    "    # Make data\n",
    "    trn_ds = trn_dl()\n",
    "    dev_ds = dev_dl()\n",
    "\n",
    "    # Epoch level\n",
    "    for e in range(epochs):\n",
    "\n",
    "        per_epoch_loss = {task_nm: [] for task_nm in tasks}\n",
    "        per_epoch_tr_metrics = {task_nm: {metric_nm: [] for metric_nm in eval_fns[task_nm].keys()} for task_nm in tasks}\n",
    "        per_epoch_vl_metrics = {task_nm: {metric_nm: [] for metric_nm in eval_fns[task_nm].keys()} for task_nm in tasks}\n",
    "\n",
    "        # Train\n",
    "        with Timer() as timer:\n",
    "\n",
    "            # Train Loop\n",
    "            for instance in tqdm(trn_ds):\n",
    "\n",
    "                # Reset the gradients.\n",
    "                opt.zero_grad()\n",
    "\n",
    "                # Forward Pass\n",
    "                outputs = train_fn(**instance)\n",
    "\n",
    "                \"\"\"\n",
    "                    Depending on instance.tasks list, do the following:\n",
    "                        - task specific loss (added to losses)\n",
    "                        - task specific metrics (added to metrics)\n",
    "                \"\"\"\n",
    "                for task_nm in instance['tasks']:\n",
    "                    loss = outputs[\"loss\"][task_nm]\n",
    "                    per_epoch_loss[task_nm].append(loss.item())\n",
    "\n",
    "                    # TODO: add other metrics here\n",
    "                    instance_metrics = compute_metrics(eval_fns[task_nm],\n",
    "                                                       logits=outputs[task_nm][\"logits\"],\n",
    "                                                       labels=outputs[task_nm][\"labels\"])\n",
    "                    for metric_nm, metric_vl in instance_metrics.items():\n",
    "                        per_epoch_tr_metrics[task_nm][metric_nm].append(metric_vl)\n",
    "\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "            # Val\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for instance in tqdm(dev_ds):\n",
    "                    outputs = predict_fn(**instance)\n",
    "\n",
    "                    for task_nm in instance[\"tasks\"]:\n",
    "                        logits = outputs[task_nm][\"logits\"]\n",
    "                        # TODO: make the label puller task specific somehow\n",
    "                        labels = instance[\"ner\"][\"gold_labels\"]\n",
    "\n",
    "                        instance_metrics = compute_metrics(eval_fns[task_nm], logits=logits, labels=labels)\n",
    "                        for metric_nm, metric_vl in instance_metrics.items():\n",
    "                            per_epoch_vl_metrics[task_nm][metric_nm].append(metric_vl)\n",
    "\n",
    "        # Bookkeep\n",
    "        for task_nm in tasks:\n",
    "            train_loss[task_nm].append(np.mean(per_epoch_loss[task_nm]))\n",
    "            train_metrics = aggregate_metrics(train_metrics, per_epoch_tr_metrics)\n",
    "            valid_metrics = aggregate_metrics(valid_metrics, per_epoch_vl_metrics)\n",
    "\n",
    "        print(f\"\\nEpoch: {e:3d}\" +\n",
    "              ''.join([f\" | {task_nm} Loss: {float(np.mean(per_epoch_loss[task_nm])):.5f}\" +\n",
    "                       ''.join([f\" | {task_nm} Tr_{metric_nm}: {float(metric_vls[-1]):.3f}\"\n",
    "                                for metric_nm, metric_vls in train_metrics[task_nm].items()]) +\n",
    "                       ''.join([f\" | {task_nm} Vl_{metric_nm}: {float(metric_vls[-1]):.3f}\"\n",
    "                                for metric_nm, metric_vls in valid_metrics[task_nm].items()])\n",
    "                       # f\" | {task_nm} Tr_c: {float(np.mean(per_epoch_tr_acc[task_nm])):.5f}\" +\n",
    "                       # f\" | {task_nm} Vl_c: {float(np.mean(per_epoch_vl_acc[task_nm])):.5f}\"\n",
    "                       for task_nm in tasks]))\n",
    "\n",
    "    return train_metrics, valid_metrics, train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make MTL A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset: str = 'ontonotes'\n",
    "epochs: int = 10\n",
    "encoder: str = \"bert-base-uncased\"\n",
    "tasks: List[str] = ('coref', 'ner', 'pruner')\n",
    "device: str = \"cpu\"\n",
    "trim: bool = False\n",
    "train_encoder: bool = False,\n",
    "ner_unweighted: bool = False\n",
    "filter_candidates_pos = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyansh/Dev/research/coref/mtl/src/dataiter.py:164: UserWarning: Processed (training ready) found on ../data/parsed/ontonotes/development/MultiTaskDatasetDump_coref_ner_pruner.pkl. But the config files mismatch.Reprocessing will commence now but will take some time. Approx. 5 min.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfc19a966314b61b0a7073646d30f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=318.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1083 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOO LONG:  reeeeeeeeeeeeeeaaaal\n",
      "TOO LONG:  586.14_588.20_\n",
      "TOO LONG:  586.14_588.20_a\n",
      "TOO LONG:  586.14_588.20_a:\n",
      "TOO LONG:  820.26_822.65_b\n",
      "TOO LONG:  820.26_822.65_b:\n",
      "TOO LONG:  965.04_967.89_\n",
      "TOO LONG:  965.04_967.89_b\n",
      "TOO LONG:  965.04_967.89_b:\n",
      "\n",
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"binary_hdim\": 2000,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"coref_dropout\": 0.3,\n",
      "  \"device\": \"cpu\",\n",
      "  \"epochs\": 10,\n",
      "  \"filter_candidates_pos_threshold\": 2000,\n",
      "  \"freeze_encoder\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_span_width\": 5,\n",
      "  \"max_top_antecedents\": 50,\n",
      "  \"metadata_feature_size\": 20,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"ner_class_weights\": [\n",
      "    0.05347951180430152,\n",
      "    18.464160137323844,\n",
      "    41.44081277574101,\n",
      "    22.342691547455527,\n",
      "    15.538011695906432,\n",
      "    23.87780164697458,\n",
      "    178.17445899011489,\n",
      "    626.7922932330827,\n",
      "    37.70179207417039,\n",
      "    316.21953532479847,\n",
      "    152.61029748283752,\n",
      "    328.0408263649779,\n",
      "    151.29469147005446,\n",
      "    272.0958792329661,\n",
      "    204.0719094247246,\n",
      "    1002.8676691729323,\n",
      "    170.39013796627492,\n",
      "    403.45251058681185,\n",
      "    1063.6475279106858\n",
      "  ],\n",
      "  \"ner_ignore_weights\": false,\n",
      "  \"ner_n_classes\": 19,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"pruner_class_weights\": [\n",
      "    0.5109255247101798,\n",
      "    23.382196199425007\n",
      "  ],\n",
      "  \"top_span_ratio\": 0.4,\n",
      "  \"transformers_version\": \"4.13.0\",\n",
      "  \"trim\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"unary_hdim\": 1000,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": \"../models/huggingface/bert-base-uncased/config\"\n",
      "}\n",
      "\n",
      "Training commences!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dir_config, dir_tokenizer, dir_encoder = get_pretrained_dirs(encoder)\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(dir_tokenizer)\n",
    "config = transformers.BertConfig(dir_config)\n",
    "config.max_span_width = 5\n",
    "config.coref_dropout = 0.3\n",
    "config.metadata_feature_size = 20\n",
    "config.unary_hdim = 1000\n",
    "config.binary_hdim = 2000\n",
    "config.top_span_ratio = 0.4\n",
    "config.max_top_antecedents = 50\n",
    "config.device = device\n",
    "config.epochs = epochs\n",
    "config.trim = trim\n",
    "config.freeze_encoder = not train_encoder\n",
    "config.ner_ignore_weights = ner_unweighted\n",
    "config.filter_candidates_pos_threshold = CONFIG['filter_candidates_pos_threshold'] \\\n",
    "    if filter_candidates_pos else -1\n",
    "\n",
    "\n",
    "if 'ner' in tasks or 'pruner' in tasks:\n",
    "    # Need to figure out the number of classes. Load a DL. Get the number. Delete the DL.\n",
    "    temp_ds = MultiTaskDataIter(\n",
    "        src=dataset,\n",
    "        config=config,\n",
    "        tasks=tasks,\n",
    "        split=\"development\",\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    if 'ner' in tasks:\n",
    "        config.ner_n_classes = deepcopy(temp_ds.ner_tag_dict.__len__())\n",
    "        config.ner_class_weights = temp_ds.estimate_class_weights('ner')\n",
    "    else:\n",
    "        config.ner_n_classes = 1\n",
    "        config.ner_class_weights = [1.0, ]\n",
    "    if 'pruner' in tasks:\n",
    "        config.pruner_class_weights = temp_ds.estimate_class_weights('pruner')\n",
    "    del temp_ds\n",
    "else:\n",
    "    config.ner_n_classes = 1\n",
    "    config.ner_class_weights = [1.0, ]\n",
    "\n",
    "# # Make the model\n",
    "# model = BasicMTL(dir_encoder, config=config)\n",
    "\n",
    "# Load the data\n",
    "train_ds = partial(\n",
    "    MultiTaskDataIter,\n",
    "    src=dataset,\n",
    "    config=config,\n",
    "    tasks=tasks,\n",
    "    split=\"train\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "# valid_ds = partial(\n",
    "#     MultiTaskDataIter,\n",
    "#     src=dataset,\n",
    "#     config=config,\n",
    "#     tasks=tasks,\n",
    "#     split=\"development\",\n",
    "#     tokenizer=tokenizer,\n",
    "# )\n",
    "\n",
    "# Make the optimizer\n",
    "# opt = make_optimizer(model=model, optimizer_class=torch.optim.SGD, lr=0.005, freeze_encoder=config.freeze_encoder)\n",
    "# opt = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# # Make the evaluation suite (may compute multiple metrics corresponding to the tasks)\n",
    "# eval_fns: Dict[str, Dict[str, Callable]] = {\n",
    "#     'ner': {'acc': ner_all,\n",
    "#             'acc_l': ner_only_annotated,\n",
    "#             'span_p': ner_span_recog_precision,\n",
    "#             'span_r': ner_span_recog_recall},\n",
    "#     'coref': {\n",
    "\n",
    "#     },\n",
    "#     'pruner': {'p': pruner_p,\n",
    "#                'r': pruner_r}\n",
    "# }\n",
    "\n",
    "print(config)\n",
    "print(\"Training commences!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyansh/Dev/research/coref/mtl/src/dataiter.py:164: UserWarning: Processed (training ready) found on ../data/parsed/ontonotes/train/MultiTaskDatasetDump_coref_ner_pruner.pkl. But the config files mismatch.Reprocessing will commence now but will take some time. Approx. 5 min.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a8e9282ac54a889330baaf20a7597e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2455.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOO LONG:  xzx620521.blogc\n",
      "TOO LONG:  xzx620521.blogcn\n",
      "TOO LONG:  xzx620521.blogcn.\n",
      "TOO LONG:  xzx...@sina.\n",
      "TOO LONG:  -lrb-c-rrb-?\n",
      "TOO LONG:  -lrb-c-rrb-?io\n",
      "TOO LONG:  -lrb-c-rrb-?io]\n",
      "TOO LONG:  -lrb-c-rrb-?io]o\n",
      "TOO LONG:  -lrb-c-rrb-?io]o?\n",
      "TOO LONG:  -lrb-c-rrb-x\n",
      "TOO LONG:  io...-lrb-c-\n",
      "TOO LONG:  io...-lrb-c-rr\n",
      "TOO LONG:  io...-lrb-c-rrb\n",
      "TOO LONG:  io...-lrb-c-rrb-\n",
      "TOO LONG:  io...-lrb-c-rrb-x\n",
      "TOO LONG:  io...-lrb-c-rrb-x.\n",
      "TOO LONG:  io...-lrb-c-rrb-x.go\n",
      "TOO LONG:  io...-lrb-c-rrb-x.goio\n",
      "TOO LONG:  io...-lrb-c-rrb-x.goio]\n",
      "TOO LONG:  339.00_347.11_a\n",
      "TOO LONG:  339.00_347.11_a:\n",
      "TOO LONG:  263.85_264.42_a:\n",
      "TOO LONG:  1622.82_1623.11_b:\n",
      "TOO LONG:  1685.48_1686.56_b\n",
      "TOO LONG:  1685.48_1686.56_b:\n",
      "TOO LONG:  114.86_118.28_a:\n",
      "TOO LONG:  387.98_388.72_\n",
      "TOO LONG:  387.98_388.72_a\n",
      "TOO LONG:  387.98_388.72_a:\n",
      "TOO LONG:  437.08_438.30_\n",
      "TOO LONG:  437.08_438.30_b\n",
      "TOO LONG:  437.08_438.30_b:\n",
      "TOO LONG:  685.61_687.71_\n",
      "TOO LONG:  685.61_687.71_a\n",
      "TOO LONG:  685.61_687.71_a:\n",
      "TOO LONG:  458.93_461.27_\n",
      "TOO LONG:  458.93_461.27_a\n",
      "TOO LONG:  458.93_461.27_a:\n",
      "TOO LONG:  959.97_962.15_\n",
      "TOO LONG:  959.97_962.15_a\n",
      "TOO LONG:  959.97_962.15_a:\n",
      "TOO LONG:  188.81_192.55_b:\n",
      "TOO LONG:  342.14_342.66_\n",
      "TOO LONG:  342.14_342.66_a\n",
      "TOO LONG:  342.14_342.66_a:\n",
      "TOO LONG:  374.10_374.55_\n",
      "TOO LONG:  374.10_374.55_a\n",
      "TOO LONG:  374.10_374.55_a:\n",
      "TOO LONG:  183.89_184.98_a:\n",
      "TOO LONG:  725.48_730.06_b\n",
      "TOO LONG:  725.48_730.06_b:\n",
      "TOO LONG:  165.00_177.54_b:\n",
      "TOO LONG:  391.97_393.19_\n",
      "TOO LONG:  391.97_393.19_b\n",
      "TOO LONG:  391.97_393.19_b:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "onto_train_di = train_ds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make MTL B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyansh/Dev/research/coref/mtl/src/dataiter.py:164: UserWarning: Processed (training ready) found on ../data/parsed/scierc/train/MultiTaskDatasetDump_ner.pkl. But the config files mismatch.Reprocessing will commence now but will take some time. Approx. 5 min.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ca70d8eadc4e63bdb513073cf252b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=349.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset: str = 'scierc'\n",
    "epochs: int = 10\n",
    "encoder: str = \"bert-base-uncased\"\n",
    "tasks: List[str] = ('ner',)\n",
    "device: str = \"cpu\"\n",
    "trim: bool = False\n",
    "train_encoder: bool = False\n",
    "ner_unweighted: bool = False\n",
    "filter_candidates_pos = True\n",
    "\n",
    "\n",
    "dir_config, dir_tokenizer, dir_encoder = get_pretrained_dirs(encoder)\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(dir_tokenizer)\n",
    "config = transformers.BertConfig(dir_config)\n",
    "config.max_span_width = 5\n",
    "config.coref_dropout = 0.3\n",
    "config.metadata_feature_size = 20\n",
    "config.unary_hdim = 1000\n",
    "config.binary_hdim = 2000\n",
    "config.top_span_ratio = 0.4\n",
    "config.max_top_antecedents = 50\n",
    "config.device = device\n",
    "config.epochs = epochs\n",
    "config.trim = trim\n",
    "config.freeze_encoder = not train_encoder\n",
    "config.ner_ignore_weights = ner_unweighted\n",
    "config.filter_candidates_pos_threshold = CONFIG['filter_candidates_pos_threshold'] \\\n",
    "    if filter_candidates_pos else -1\n",
    "\n",
    "\n",
    "# if 'ner' in tasks or 'pruner' in tasks:\n",
    "if False:\n",
    "    # Need to figure out the number of classes. Load a DL. Get the number. Delete the DL.\n",
    "    temp_ds = MultiTaskDataIter(\n",
    "        src=dataset,\n",
    "        config=config,\n",
    "        tasks=tasks,\n",
    "        split=\"dev\",\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    if 'ner' in tasks:\n",
    "        config.ner_n_classes = deepcopy(temp_ds.ner_tag_dict.__len__())\n",
    "        config.ner_class_weights = temp_ds.estimate_class_weights('ner')\n",
    "    else:\n",
    "        config.ner_n_classes = 1\n",
    "        config.ner_class_weights = [1.0, ]\n",
    "    if 'pruner' in tasks:\n",
    "        config.pruner_class_weights = temp_ds.estimate_class_weights('pruner')\n",
    "    del temp_ds\n",
    "else:\n",
    "    config.ner_n_classes = 1\n",
    "    config.ner_class_weights = [1.0, ]\n",
    "\n",
    "# # Make the model\n",
    "# model = BasicMTL(dir_encoder, config=config)\n",
    "\n",
    "# Load the data\n",
    "train_ds = partial(\n",
    "    MultiTaskDataIter,\n",
    "    src=dataset,\n",
    "    config=config,\n",
    "    tasks=tasks,\n",
    "    split=\"train\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "sci_train_ds = train_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tasks': ['ner'],\n",
       " 'input_ids': tensor([[ 1999,  2023,  3259,  1010,  2057,  2556,  1037,  3617,  4742, 13151,\n",
       "           1006, 16233,  2361,  1007,  7375,  1997,  2613,  1011,  2051,  7778,\n",
       "           2376,  7584,  1006, 18315,  1007,  2005,  4333,  4613, 22415,  1998,\n",
       "          16175, 28221, 15465,  2389,  4613, 22415,  1012,  2004,  1037,  4333,\n",
       "           4613,  8278,  1010,  2057,  3579,  2006,  2512,  1011, 19525, 20227,\n",
       "           1006, 15125,  1007,  1010,  2029,  2064,  2022,  2109,  1999,  8146,\n",
       "           2073, 19525,  4613,  2003,  2025, 11701,  1012, 16175, 28221, 15465,\n",
       "           2389,  4613,  2003,  2028,  1997,  1996,  5171,  4127,  1997, 21862,\n",
       "          18143,  3351,  2389,  4613,  2550,  2011,  2019,  4522,  4092,  4118,\n",
       "           2005,  2474, 18143,  3351,  6593,  8462,  2229,  1012,  2174,  1010,\n",
       "           1996,  2614,  3737,  1997, 15125,  1998, 16175, 28221, 15465,  2389,\n",
       "           4613, 17567,  2013,  3768,  1997,  3019,  2791,  1012, 18315,  2038,\n",
       "          10003,  2000,  2022,  2028,  1997,  1996, 10015,  8107,  2000,  4769,\n",
       "           2023,  3291,  1010,  1998,  2009,  2038,  2042,  5147,  7528,  2006,\n",
       "           5733,  2007,  7182, 15078,  4219,  1012,  2019,  7375,  2006,  5733,\n",
       "           2008,  2024,  3811, 12109,  2021,  2031,  3132, 15078,  4219,  2052,\n",
       "           6551,  9002,  2000,  2049,  6742,  2224,  1012,  1999,  2023,  3259,\n",
       "           2057,  2582, 10408,  2613,  1011,  2051, 18315,  2006,  1037, 16233,\n",
       "           2361,  1012,  2000, 10408,  1996,  2048,  4613, 22415,  3001,  2241,\n",
       "           2006,  2613,  1011,  2051, 18315,  1010,  2028,  2013, 15125,  2000,\n",
       "           1037,  3990,  2376,  1998,  1996,  2060,  2013, 16175, 28221, 15465,\n",
       "           2389,  4613,  2000,  1037,  3019,  2376,  1010,  2057, 16599,  2195,\n",
       "           4725,  2005,  8161, 15078,  3465,  2096, 15224,  7584, 10640,  1012,\n",
       "           2057,  6204,  6388,  9312,  2015,  1998,  2265,  2008,  2613,  1011,\n",
       "           2051, 18315,  2003,  5214,  1997,  2770,  2006,  1037, 16233,  2361,\n",
       "           2007,  2210, 16627,  1012,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " 'word_map': tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  11,  12,\n",
       "          13,  14,  15,  15,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,\n",
       "          25,  26,  27,  27,  27,  27,  28,  29,  30,  31,  32,  33,  34,  35,\n",
       "          36,  37,  38,  39,  40,  40,  40,  41,  42,  43,  44,  45,  46,  47,\n",
       "          48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  59,  59,\n",
       "          59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  68,  68,  68,  69,\n",
       "          70,  71,  72,  73,  74,  75,  76,  77,  77,  77,  77,  77,  77,  78,\n",
       "          79,  80,  81,  82,  83,  84,  85,  86,  87,  87,  87,  87,  88,  89,\n",
       "          90,  91,  92,  93,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
       "         103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "         117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "         131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144,\n",
       "         145, 146, 147, 148, 149, 150, 150, 150, 151, 152, 153, 154, 154, 155,\n",
       "         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 165, 165, 166, 167,\n",
       "         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 179, 179,\n",
       "         179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "         193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 202, 203, 204, 205,\n",
       "         206, 206, 206, 207, 208, 209, 210, 211, 212, 213, 214, 214, 215, 216,\n",
       "         217, 218]),\n",
       " 'sentence_map': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6,\n",
       "         6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "         7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "         7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "         8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]),\n",
       " 'n_words': 219,\n",
       " 'n_subwords': 254,\n",
       " 'candidate_starts': tensor([  0,   0,   0,  ..., 252, 252, 253]),\n",
       " 'candidate_ends': tensor([  0,   1,   2,  ..., 252, 253, 253]),\n",
       " 'ner': {'gold_starts': tensor([  7,  16,  26,  30,  39,  46,  61,  67,  79,  88,  91, 101, 104, 104,\n",
       "          118, 134, 140, 142, 149, 156, 173, 179, 186, 191, 196, 198, 201, 205,\n",
       "          207, 214, 220, 223, 227, 238, 248]),\n",
       "  'gold_ends': tensor([ 14,  24,  28,  35,  41,  52,  62,  71,  83,  89,  96, 102, 104, 110,\n",
       "          118, 134, 140, 144, 149, 158, 176, 180, 188, 194, 196, 198, 202, 205,\n",
       "          211, 215, 220, 224, 228, 241, 249]),\n",
       "  'gold_labels': tensor([0, 0, 0,  ..., 0, 0, 0])}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sci_train_ds[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2455, 346, 2801)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la = onto_train_di.__len__()\n",
    "lb = sci_train_ds.__len__()\n",
    "\n",
    "la, lb, la+lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_ratio = [1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "llen = la + lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1400, 1400]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pointers = [int(x* llen / float(sum(sampling_ratio))) for x in sampling_ratio]\n",
    "pointers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Testing Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from eval import Evaluator, NERAcc, NERSpanRecognitionPR, PrunerPR, CorefBCubed, CorefMUC, CorefCeafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_bench = Evaluator(\n",
    "    predict_fn = model.pred_with_labels,\n",
    "    dataset_partial = valid_ds,\n",
    "    metrics = [NERAcc(), NERSpanRecognitionPR(), PrunerPR(), CorefBCubed(), CorefMUC(), CorefCeafe()],\n",
    "    device = 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eval_bench.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Eval for Coref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3,
     25,
     40,
     44
    ],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def b_cubed(clusters, mention_to_gold):\n",
    "    num, dem = 0, 0\n",
    "\n",
    "    for c in clusters:\n",
    "        if len(c) == 1:\n",
    "            continue\n",
    "\n",
    "        gold_counts = Counter()\n",
    "        correct = 0\n",
    "        for m in c:\n",
    "            if m in mention_to_gold:\n",
    "                gold_counts[tuple(mention_to_gold[m])] += 1\n",
    "        for c2, count in gold_counts.items():\n",
    "            if len(c2) != 1:\n",
    "                correct += count * count\n",
    "\n",
    "        num += correct / float(len(c))\n",
    "        dem += len(c)\n",
    "\n",
    "    return num, dem\n",
    "\n",
    "\n",
    "def muc(clusters, mention_to_gold):\n",
    "    tp, p = 0, 0\n",
    "    for c in clusters:\n",
    "        p += len(c) - 1\n",
    "        tp += len(c)\n",
    "        linked = set()\n",
    "        for m in c:\n",
    "            if m in mention_to_gold:\n",
    "                linked.add(mention_to_gold[m])\n",
    "            else:\n",
    "                tp -= 1\n",
    "        tp -= len(linked)\n",
    "    return tp, p\n",
    "\n",
    "\n",
    "def phi4(c1, c2):\n",
    "    return 2 * len([m for m in c1 if m in c2]) / float(len(c1) + len(c2))\n",
    "\n",
    "\n",
    "def ceafe(clusters, gold_clusters):\n",
    "    clusters = [c for c in clusters if len(c) != 1]\n",
    "    scores = np.zeros((len(gold_clusters), len(clusters)))\n",
    "    for i in range(len(gold_clusters)):\n",
    "        for j in range(len(clusters)):\n",
    "            scores[i, j] = phi4(gold_clusters[i], clusters[j])\n",
    "    matching = linear_assignment(-scores)\n",
    "    similarity = sum(scores[matching[0], matching[1]])\n",
    "\n",
    "    # similarity = sum(scores[matching[:, 0], matching[:, 1]])\n",
    "    return similarity, len(clusters), similarity, len(gold_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for i, instance in enumerate(dl):\n",
    "    outputs = model.pred_with_labels(**instance)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "instance['coref'].keys(), outputs['coref'].keys(), outputs.keys(), outputs['coref']['eval'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('=None, '.join(['clusters', 'gold_clusters', 'mention_to_predicted', 'mention_to_gold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ll =  outputs['coref']['eval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ceafe(ll['clusters'], ll['gold_clusters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "phi4(ll['clusters'], ll['gold_clusters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "muc(ll['clusters'], ll['mention_to_gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "b_cubed(ll['clusters'], ll['mention_to_gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
