{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing paths from /home/priyansh/Dev/research/coref/mtl/src\n"
     ]
    }
   ],
   "source": [
    "import click\n",
    "import torch\n",
    "import numpy as np\n",
    "import transformers\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "from mytorch.utils.goodies import Timer\n",
    "from typing import List, Callable, Iterable, Dict\n",
    "\n",
    "# Local imports\n",
    "try:\n",
    "    import _pathfix\n",
    "except ImportError:\n",
    "    from . import _pathfix\n",
    "from config import LOCATIONS as LOC\n",
    "from models.multitask import BasicMTL\n",
    "from dataiter import MultiTaskDataset\n",
    "from utils.exceptions import BadParameters\n",
    "from eval import ner_all, ner_only_annotated, ner_span_recog_recall, ner_span_recog_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_optimizer(model, optimizer_class: Callable, lr: float, freeze_encoder: bool):\n",
    "    if freeze_encoder:\n",
    "        return optimizer_class(\n",
    "            [param for name, param in model.named_parameters() if not name.startswith(\"encoder\")],\n",
    "            lr=lr\n",
    "        )\n",
    "    else:\n",
    "        return optimizer_class(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "def get_pretrained_dirs(nm: str):\n",
    "    \"\"\"Check if the given nm is stored locally. If so, load that. Else, pass it on as is.\"\"\"\n",
    "    plausible_parent_dir: Path = LOC.root / \"models\" / \"huggingface\" / nm\n",
    "\n",
    "    if (\n",
    "            (plausible_parent_dir / \"config\").exists()\n",
    "            and (plausible_parent_dir / \"tokenizer\").exists()\n",
    "            and (plausible_parent_dir / \"encoder\").exists()\n",
    "    ):\n",
    "        return (\n",
    "            str(plausible_parent_dir / \"config\"),\n",
    "            str(plausible_parent_dir / \"tokenizer\"),\n",
    "            str(plausible_parent_dir / \"encoder\"),\n",
    "        )\n",
    "    else:\n",
    "        return nm, nm, nm\n",
    "\n",
    "\n",
    "def compute_metrics(metrics: Dict[str, Callable], logits, labels) -> Dict[str, float]:\n",
    "    return {metric_nm: metric_fn(logits=logits, labels=labels).item() for metric_nm, metric_fn in metrics.items()}\n",
    "\n",
    "\n",
    "def aggregate_metrics(inter_epoch: dict, intra_epoch: dict):\n",
    "    for task_nm in inter_epoch.keys():\n",
    "        for metric_nm, metric_list in intra_epoch[task_nm].items():\n",
    "            inter_epoch[task_nm][metric_nm].append(np.mean(metric_list))\n",
    "    return inter_epoch\n",
    "\n",
    "\n",
    "def simplest_loop(\n",
    "        epochs: int,\n",
    "        tasks: Iterable[str],\n",
    "        opt: torch.optim,\n",
    "        train_fn: Callable,\n",
    "        predict_fn: Callable,\n",
    "        trn_dl: Callable,\n",
    "        dev_dl: Callable,\n",
    "        eval_fns: dict,\n",
    ") -> (list, list, list):\n",
    "    train_loss = {task_nm: [] for task_nm in tasks}\n",
    "    train_metrics = {task_nm: {metric_nm: [] for metric_nm in eval_fns[task_nm].keys()} for task_nm in tasks}\n",
    "    valid_metrics = {task_nm: {metric_nm: [] for metric_nm in eval_fns[task_nm].keys()} for task_nm in tasks}\n",
    "\n",
    "    # Make data\n",
    "    trn_ds = trn_dl()\n",
    "    dev_ds = dev_dl()\n",
    "\n",
    "    # Epoch level\n",
    "    for e in range(epochs):\n",
    "\n",
    "        per_epoch_loss = {task_nm: [] for task_nm in tasks}\n",
    "        per_epoch_tr_metrics = {task_nm: {metric_nm: [] for metric_nm in eval_fns[task_nm].keys()} for task_nm in tasks}\n",
    "        per_epoch_vl_metrics = {task_nm: {metric_nm: [] for metric_nm in eval_fns[task_nm].keys()} for task_nm in tasks}\n",
    "\n",
    "        # Train\n",
    "        with Timer() as timer:\n",
    "\n",
    "            # Train Loop\n",
    "            for instance in tqdm(trn_ds):\n",
    "\n",
    "                # Reset the gradients.\n",
    "                opt.zero_grad()\n",
    "\n",
    "                # Forward Pass\n",
    "                outputs = train_fn(**instance)\n",
    "\n",
    "                \"\"\"\n",
    "                    Depending on instance.tasks list, do the following:\n",
    "                        - task specific loss (added to losses)\n",
    "                        - task specific metrics (added to metrics)\n",
    "                \"\"\"\n",
    "                for task_nm in instance['tasks']:\n",
    "                    loss = outputs[\"loss\"][task_nm]\n",
    "                    per_epoch_loss[task_nm].append(loss.item())\n",
    "\n",
    "                    # TODO: add other metrics here\n",
    "                    instance_metrics = compute_metrics(eval_fns[task_nm],\n",
    "                                                       logits=outputs[task_nm][\"logits\"],\n",
    "                                                       labels=outputs[task_nm][\"labels\"])\n",
    "                    for metric_nm, metric_vl in instance_metrics.items():\n",
    "                        per_epoch_tr_metrics[task_nm][metric_nm].append(metric_vl)\n",
    "\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "            # Val\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for instance in tqdm(dev_ds):\n",
    "                    outputs = predict_fn(**instance)\n",
    "\n",
    "                    for task_nm in instance[\"tasks\"]:\n",
    "                        logits = outputs[task_nm][\"logits\"]\n",
    "                        # TODO: make the label puller task specific somehow\n",
    "                        labels = instance[\"ner\"][\"gold_labels\"]\n",
    "\n",
    "                        instance_metrics = compute_metrics(eval_fns[task_nm], logits=logits, labels=labels)\n",
    "                        for metric_nm, metric_vl in instance_metrics.items():\n",
    "                            per_epoch_vl_metrics[task_nm][metric_nm].append(metric_vl)\n",
    "\n",
    "        # Bookkeep\n",
    "        for task_nm in tasks:\n",
    "            train_loss[task_nm].append(np.mean(per_epoch_loss[task_nm]))\n",
    "            train_metrics = aggregate_metrics(train_metrics, per_epoch_tr_metrics)\n",
    "            valid_metrics = aggregate_metrics(valid_metrics, per_epoch_vl_metrics)\n",
    "\n",
    "        print(f\"\\nEpoch: {e:3d}\" +\n",
    "              ''.join([f\" | {task_nm} Loss: {float(np.mean(per_epoch_loss[task_nm])):.5f}\" +\n",
    "                       ''.join([f\" | {task_nm} Tr_{metric_nm}: {float(metric_vls[-1]):.3f}\"\n",
    "                                for metric_nm, metric_vls in train_metrics[task_nm].items()]) +\n",
    "                       ''.join([f\" | {task_nm} Vl_{metric_nm}: {float(metric_vls[-1]):.3f}\"\n",
    "                                for metric_nm, metric_vls in valid_metrics[task_nm].items()])\n",
    "                       # f\" | {task_nm} Tr_c: {float(np.mean(per_epoch_tr_acc[task_nm])):.5f}\" +\n",
    "                       # f\" | {task_nm} Vl_c: {float(np.mean(per_epoch_vl_acc[task_nm])):.5f}\"\n",
    "                       for task_nm in tasks]))\n",
    "\n",
    "    return train_metrics, valid_metrics, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: str = 'ontonotes'\n",
    "epochs: int = 10\n",
    "encoder: str = \"bert-base-uncased\"\n",
    "tasks: List[str] = ('ner',)\n",
    "device: str = \"cpu\"\n",
    "trim: bool = False\n",
    "train_encoder: bool = False,\n",
    "ner_unweighted: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled 542 instances from ../data/parsed/ontonotes/development/MultiTaskDatasetDump_ner.pkl.\n",
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"binary_hdim\": 2000,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"coref_dropout\": 0.3,\n",
      "  \"device\": \"cpu\",\n",
      "  \"epochs\": 10,\n",
      "  \"freeze_encoder\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_span_width\": 5,\n",
      "  \"max_top_antecedents\": 50,\n",
      "  \"metadata_feature_size\": 20,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"ner_class_weights\": [\n",
      "    0.05345022075992995,\n",
      "    22.380981866430783,\n",
      "    52.14050199892841,\n",
      "    19.751830629674156,\n",
      "    18.302204797314893,\n",
      "    21.238730798287584,\n",
      "    216.17993848257007,\n",
      "    365.84297281665704,\n",
      "    39.0747776130467,\n",
      "    405.99646983311936,\n",
      "    86.69716282894737,\n",
      "    536.9630730050934,\n",
      "    198.7564807541241,\n",
      "    405.99646983311936,\n",
      "    104.36272892262004,\n",
      "    1280.4504048582996,\n",
      "    196.41127154168606,\n",
      "    398.7031200756382,\n",
      "    1902.3834586466166\n",
      "  ],\n",
      "  \"ner_ignore_weights\": false,\n",
      "  \"ner_n_classes\": 19,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"top_span_ratio\": 0.4,\n",
      "  \"transformers_version\": \"4.13.0\",\n",
      "  \"trim\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"unary_hdim\": 1000,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": \"../models/huggingface/bert-base-uncased/config\"\n",
      "}\n",
      "\n",
      "Training commences!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dir_config, dir_tokenizer, dir_encoder = get_pretrained_dirs(encoder)\n",
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(dir_tokenizer)\n",
    "config = transformers.BertConfig(dir_config)\n",
    "config.max_span_width = 5\n",
    "config.coref_dropout = 0.3\n",
    "config.metadata_feature_size = 20\n",
    "config.unary_hdim = 1000\n",
    "config.binary_hdim = 2000\n",
    "config.top_span_ratio = 0.4\n",
    "config.max_top_antecedents = 50\n",
    "config.device = device\n",
    "config.epochs = epochs\n",
    "config.trim = trim\n",
    "config.freeze_encoder = not train_encoder\n",
    "config.ner_ignore_weights = ner_unweighted\n",
    "\n",
    "# Need to figure out the number of classes. Load a DL. Get the number. Delete the DL.\n",
    "temp_ds = MultiTaskDataset(\n",
    "    src=dataset,\n",
    "    config=config,\n",
    "    tasks=(\"ner\",),\n",
    "    split=\"development\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "config.ner_n_classes = deepcopy(temp_ds.ner_tag_dict.__len__())\n",
    "config.ner_class_weights = temp_ds.estimate_class_weights()\n",
    "del temp_ds\n",
    "\n",
    "# Make the model\n",
    "model = BasicMTL(dir_encoder, config=config)\n",
    "\n",
    "# Load the data\n",
    "train_ds = partial(\n",
    "    MultiTaskDataset,\n",
    "    src=dataset,\n",
    "    config=config,\n",
    "    tasks=tasks,\n",
    "    split=\"train\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "valid_ds = partial(\n",
    "    MultiTaskDataset,\n",
    "    src=dataset,\n",
    "    config=config,\n",
    "    tasks=tasks,\n",
    "    split=\"development\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Make the optimizer\n",
    "opt = make_optimizer(model=model, optimizer_class=torch.optim.SGD, lr=0.005, freeze_encoder=config.freeze_encoder)\n",
    "# opt = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# Make the evaluation suite (may compute multiple metrics corresponding to the tasks)\n",
    "eval_fns = {\n",
    "    'ner': {'acc': ner_all,\n",
    "            'acc_l': ner_only_annotated,\n",
    "            'span_p': ner_span_recog_precision,\n",
    "            'span_r': ner_span_recog_recall},\n",
    "    'coref': {\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "print(config)\n",
    "print(\"Training commences!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled 3718 instances from ../data/parsed/ontonotes/train/MultiTaskDatasetDump_ner.pkl.\n"
     ]
    }
   ],
   "source": [
    "dl = train_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, instance in enumerate(dl):\n",
    "    if i == 1419:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance['ner']['gold_labels'].nonzero().shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gold_starts': tensor([60, 81]),\n",
       " 'gold_ends': tensor([68, 86]),\n",
       " 'gold_labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance['ner']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
